{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4feafb4-a93f-469b-8f91-913845131538",
   "metadata": {},
   "source": [
    "# Ans : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e729a-9386-4499-8746-46c6b949a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Elastic Net Regression is a linear regression model that combines the penalties of Lasso (L1) and Ridge (L2) methods.\n",
    "It aims to improve model prediction accuracy and interpretability by adding a regularization term that penalizes the model's complexity.\n",
    "\n",
    "Lasso Regression (L1): Shrinks some coefficients to zero, effectively performing feature selection.\n",
    "Ridge Regression (L2): Shrinks coefficients but does not set them to zero.\n",
    "Elastic Net: Balances between L1 and L2 penalties, useful for handling correlated features and when the number of predictors exceeds the number of observations.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0590b0-01c3-4b61-b21d-ae29b82e53e8",
   "metadata": {},
   "source": [
    "# Ans : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5fd74-7689-477b-a226-932e18834066",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimal values for the regularization parameters (alpha and l1_ratio) are usually chosen using cross-validation. Grid search or randomized \n",
    "search methods can be used to systematically explore a range of parameter values and identify the combination that minimizes prediction\n",
    "error on a validation set.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a87e6c-50f0-4d9c-9824-4ec5f93dd2c2",
   "metadata": {},
   "source": [
    "# Ans : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051b784-e8a4-4024-b1e5-478f7dfa2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Advantages:\n",
    "\n",
    "Combines the strengths of Lasso and Ridge regression.\n",
    "Performs well when there are multiple correlated predictors.\n",
    "Can handle situations where the number of predictors exceeds the number of observations.\n",
    "Disadvantages:\n",
    "\n",
    "Computationally intensive compared to simpler methods.\n",
    "Requires careful tuning of hyperparameters (alpha and l1_ratio).\n",
    "Interpretation of the model can be complex due to the combination of L1 and L2 penalties.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdeb468-23c2-4cd2-9c7a-4a90790d4bf1",
   "metadata": {},
   "source": [
    "# Ans : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831be76b-096b-4404-970e-34bdc30a04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Genomic data analysis: Handling high-dimensional data with many correlated features.\n",
    "Econometrics: Dealing with economic models where predictors can be highly correlated.\n",
    "Finance: Risk management and portfolio optimization where multicollinearity is common.\n",
    "Marketing: Predicting customer behavior with many potential predictors.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2edfc-8566-485a-b0f5-3dcf4e9b5b23",
   "metadata": {},
   "source": [
    "# Ans : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e585a-60db-4b50-acff-666f1001c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Coefficients in Elastic Net Regression are interpreted similarly to other linear models:\n",
    "\n",
    "The magnitude and sign of a coefficient indicate the strength and direction of the relationship between the predictor and the response variable.\n",
    "Non-zero coefficients suggest that the corresponding predictors are relevant to the model.\n",
    "Zero coefficients indicate that the predictors have been excluded from the model due to regularization.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2aeb1f-d50a-4d94-b28e-d1003016617c",
   "metadata": {},
   "source": [
    "# Ans : 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d4da3-3058-445c-a36d-d3d6083c8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Handling missing values can be done by:\n",
    "\n",
    "Imputation: Replacing missing values with statistical measures (mean, median, mode) or using advanced imputation techniques like k-nearest neighbors (KNN) or multiple imputation.\n",
    "Removing observations: If the percentage of missing values is small, affected observations can be removed.\n",
    "Indicator variables: Creating indicator variables to flag missing data can sometimes be useful.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc2425-6dc4-4f3e-8f56-5c57cc265b9d",
   "metadata": {},
   "source": [
    "# Ans : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bba62-6ca1-4997-ab3d-7a55406c7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Elastic Net Regression performs feature selection by shrinking some coefficients to zero. The L1 penalty component encourages sparsity,\n",
    "setting some coefficients to zero, while the L2 penalty ensures that correlated features are not arbitrarily chosen. After training the\n",
    "model, features with non-zero coefficients are selected as important.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d848db2-1791-4863-974b-62cd01f6d962",
   "metadata": {},
   "source": [
    "# Ans : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af13b8-ecd8-4736-a393-ce4b35d2fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling a model:\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Assuming 'model' is your trained ElasticNet model\n",
    "with open('elastic_net_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "# Unpickling a model:\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "with open('elastic_net_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87375f62-b78d-4dca-9670-9d82bca62a07",
   "metadata": {},
   "source": [
    "# Ans : 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382a290-dbc6-472c-a953-93a989ca4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pickling a model allows you to save a trained model to disk, which can be reloaded later without needing to retrain it. This is useful for:\n",
    "\n",
    "Deployment: Moving models to production environments.\n",
    "Persistence: Keeping a record of models for future use or comparison.\n",
    "Sharing: Distributing trained models to others.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
